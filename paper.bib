@article{bioinformatics,
    author = {Afiaz, Awan and Ivanov, Andrey A and Chamberlin, John and Hanauer, David and Savonen, Candace L and Goldman, Mary J and Morgan, Martin and Reich, Michael and Getka, Alexander and Holmes, Aaron and Pati, Sarthak and Knight, Dan and Boutros, Paul C and Bakas, Spyridon and Caporaso, J Gregory and Del Fiol, Guilherme and Hochheiser, Harry and Haas, Brian and Schloss, Patrick D and Eddy, James A and Albrecht, Jake and Fedorov, Andrey and Waldron, Levi and Hoffman, Ava M and Bradshaw, Richard L and Leek, Jeffrey T and Wright, Carrie},
    title = {Best practices to evaluate the impact of biomedical research software—metric collection beyond citations},
    journal = {Bioinformatics},
    volume = {40},
    number = {8},
    pages = {btae469},
    year = {2024},
    month = {07},
    abstract = {Software is vital for the advancement of biology and medicine. Impact evaluations of scientific software have primarily emphasized traditional citation metrics of associated papers, despite these metrics inadequately capturing the dynamic picture of impact and despite challenges with improper citation.To understand how software developers evaluate their tools, we conducted a survey of participants in the Informatics Technology for Cancer Research (ITCR) program funded by the National Cancer Institute (NCI). We found that although developers realize the value of more extensive metric collection, they find a lack of funding and time hindering. We also investigated software among this community for how often infrastructure that supports more nontraditional metrics were implemented and how this impacted rates of papers describing usage of the software. We found that infrastructure such as social media presence, more in-depth documentation, the presence of software health metrics, and clear information on how to contact developers seemed to be associated with increased mention rates. Analysing more diverse metrics can enable developers to better understand user engagement, justify continued funding, identify novel use cases, pinpoint improvement areas, and ultimately amplify their software’s impact. Challenges are associated, including distorted or misleading metrics, as well as ethical and security concerns. More attention to nuances involved in capturing impact across the spectrum of biomedical software is needed. For funders and developers, we outline guidance based on experience from our community. By considering how we evaluate software, we can empower developers to create tools that more effectively accelerate biological and medical research progress.More information about the analysis, as well as access to data and code is available at https://github.com/fhdsl/ITCR\_Metrics\_manuscript\_website.},
    issn = {1367-4811},
    doi = {10.1093/bioinformatics/btae469},
    url = {https://doi.org/10.1093/bioinformatics/btae469},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/40/8/btae469/58723814/btae469.pdf},
}


@article{wickham_tidy_2014,
	title = {Tidy {Data}},
	volume = {59},
	copyright = {Copyright (c) 2013 Hadley  Wickham},
	issn = {1548-7660},
	url = {https://doi.org/10.18637/jss.v059.i10},
	doi = {10.18637/jss.v059.i10},
	abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
	language = {en},
	urldate = {2025-02-12},
	journal = {Journal of Statistical Software},
	author = {Wickham, Hadley},
	month = sep,
	year = {2014},
	pages = {1--23},
}

@misc{dashboard,
  url={https://hutchdatascience.org/metricminer-dashboard/},
  journal={Metricminer Dashboard},
  publisher={Fred Hutchinson Cancer Center},
  author={Savonen, Candace}
  } 
